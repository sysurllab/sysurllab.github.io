<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><meta name="baidu-site-verification" content="codeva-Hjc1L3MIUA"><title>yuchao.tech</title><meta name="author" content="余超(Yu Chao)"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">yuchao.tech</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/Home/home.html"> Home</a></li><li class="menus_item"><a class="site-page" href="/Publications/publications.html"> Publications</a></li><li class="menus_item"><a class="site-page" href="/"> About</a></li><li class="menus_item"><a class="site-page" href="/"> Contact Us</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/yuchao.png" onerror="this.onerror=null;this.src='/img/profile.png'" alt="avatar"></div><div class="author-discrip"><h3>余超(Yu Chao)</h3><p class="author-bio">中山大学计算机学院先进网络与计算系统研究所副教授</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-twitter" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-facebook-square" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://github.com/sysurllab" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-stack-overflow" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-weibo" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-weixin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-qq" aria-hidden="true"></i></a></li><li><a class="social-icon" href="mailto:yuchao3@mail.sysu.edu.cn" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fas fa-rss" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="/" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li><li><a class="e-social-link" href="/" target="_blank"><i class="fab fa-orcid" aria-hidden="true"></i><span>ORCID</span></a></li></ul></div><a class="cv-links" href="/attaches/CV.pdf" target="_blank"><i class="fas fa-file-pdf" aria-hidden="true"><span>My Detail CV.</span></i></a></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title"></h2><article><p>期刊论文</p>
<ol>
<li>余超, 董银昭, 郭宪, 冯旸赫, 卓汉逵, 张强，一种基于结构交互驱动的机器人深度强化学习控制方法，软件学报，2023</li>
<li>Chao Yu, Qikai Huang, Towards more efficient and robust evaluation of sepsis treatment with deep reinforcement learning, BMC Medical Informatics and Decision Making, 2023</li>
<li>Chao Yu, JIming Liu and Shamim Nemati. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.08796v1">Reinforcement Learning in Healthcare: A Survey</a> ACM Computing Survey, 2021.</li>
<li>Chao Yu, et al. Supervised-actor-critic reinforcement learning for intelligent mechanical ventilation and sedative dosing in intensive care units. BMC Medical Informatics and Decision Making, 2020 (IF:2.134)</li>
<li>Chao Yu, Yinzhao Dong, Yangning Li, Yatong Chen Distributed multi-agent deep reinforcement learning for cooperative multi-robot pursuit , The Journal of Engineering, 2020.</li>
<li>Chao Yu, Xin Wang, Xin Xu, et al. Distributed Multiagent Coordinated Learning for Autonomous Driving in Highways Based on Dynamic Coordination Graphs. <strong>IEEE Transactions Intelligent Transportation Systems</strong>, doi: 10.1109&#x2F;TITS.2019.2893683, 2019. (IF:4.051)</li>
<li>Chao Yu, Jiming Liu and Hongyi Zhao. Inverse Reinforcement Learning for Intelligent Mechanical Ventilation and Sedative Dosing in Intensive Care Units. BMC Medical Informatics and Decision Making, 2019. (IF:2.134)</li>
<li>Chao Yu, Yinzhao Dong and Jiming Liu, and Guoqi Ren. Incorporating Causal Factors into Reinforcement Learning for Dynamic Treatment Regimes in HIV. BMC Medical Informatics and Decision Making, 2019. (IF:2.134)</li>
<li>Bingcai Chen, Chao Yu*, Qishaui Diao, Rui Liu and Yuliang Wang. Social or Individual Learning? An Aggregated Solution for Coordination in Multiagent Systems. Journal of Systems Science and Systems Engineering, 27 (2), 180-200 (IF:0.766)</li>
<li>Fuxin Zhang, Guozhen Tan, Chao Yu. Fair Transmission Rate Adjustment in Cooperative Vehicle Safety Systems based on Multi-Agent Model Predictive Control. <strong>IEEE Transactions on Vehicular Technology.</strong> 66(7): 6115-6129, 2017. (IF:4.432)</li>
<li>Chao Yu, Minjie Zhang, Fenghui Ren, and Guozhen Tan. Emotional Multiagent Reinforcement Learning in Spatial Social Dilemmas, <strong>IEEE Transactions on Neural Networks and Learning Systems</strong>. 26(12), 3083-3096, 2015. (<strong>4.051</strong>)</li>
<li>Chao Yu, Minjie Zhang, Fenghui Ren, and Guozhen Tan. Multiagent Learning of Coordination in Loosely Coupled Multiagent Systems, <strong>IEEE Transactions on Cybernetics</strong>. 45(12), 2853-2867, 2015. (<strong>IF:10.387</strong>）</li>
<li>Chao Yu, Minjie Zhang and Fenghui Ren and Guozhen Tan. Emergence of Social Norms through Collective Learning in Networked Multiagent Systems, <strong>IEEE Transactions on Cybernetics</strong>, 44(12): 2342-2355, 2014. (<strong>IF:10.387</strong>)</li>
</ol>
<p>会议论文</p>
<ol>
<li>Qian Lin, Bo Tang, Zifan Wu, Chao Yu*, et al. Safe Offline Reinforcement Learning with Real-Time Budget Constraints, ICML2023</li>
<li>Wenxuan Zhu, Chao Yu*, Qiang Zhang. Causal Deep Reinforcement Learning using Observational Data, IJCAI2023</li>
<li>Chao Yu, Hierarchical Mean-Field Deep Reinforcement Learning for Large-Scale Multiagent Systems, AAAI2023</li>
<li>Zifan Wu, Chao Yu*, et al. Models as Agents: Optimizing Multi-Step Predictions of Interactive Local Models in Model-Based Multi-Agent Reinforcement Learning, AAAI2023</li>
<li>Pei Xu, Junge Zhang, Qiyue Yin, Chao Yu, Yaodong Yang, Kaiqi Huang. Subspace-Aware Exploration for Sparse-Reward Multi-Agent Tasks, AAAI2023</li>
<li>Yucong Zhang, Chao Yu*, et al. EXPODE: EXploiting POlicy Discrepancy for Efficient Exploration in Multi-agent Reinforcement Learning, AAMAS2023</li>
<li>Zongkai Liu, Chao Yu*, et al. A Unified Diversity Measure for Multiagent Reinforcement Learning, NeurlPS2022.</li>
<li>Zifan Wu, Chao Yu*, et al. Plan To Predict: Learning an Uncertainty-Foreseeing Model For Model-Based Reinforcement Learning, NeurlPS2022.</li>
<li>Mu Jin, Zhihao Ma, Kebin Jin, Hankui Zhuo, Chen Chen, Chao Yu, SORL: Automatic Symbolic Option Discovery for Facilitating Deep Reinforcement Learning, AAAI2022</li>
<li>Zifan Wu, Chao Yu*, et al. Coordinated Proximal Policy Optimization, NeurlPS2021.</li>
<li>Chao Yu, et al. Decomposed Deep Reinforcement Learning for Robotic Control, AAMAS2020.</li>
<li>Chao Yu, et al. Interactive RL via Online Human Demonstrations, AAMAS2020.</li>
<li>Chao Yu, Guozhen Tan, The Price of Governance: A Middle Ground Solution to Coordination in Organizational Control, IJCAI2019.</li>
<li>Yaodong yang, Jianye Hao and Chao Yu, Large-Scale Home Energy Management Using Entropy-Based Collective Multiagent Reinforcement Learning Framework. IJCAI2019</li>
<li>Chao Yu, Xin Wang, Zhanbo Feng: Coordinated Multiagent Reinforcement Learning for Teams of Mobile Sensing Robots. AAMAS 2019: 2297-2299</li>
<li>Chao Yu, Guoqi Ren and Jiming Liu, Deep Inverse Reinforcement Learning for Sepsis Treatment, 2019 IEEE International Conference on Healthcare Informatics, 2019. (EI)</li>
<li>Chao Yu, Yinzhao Dong and Xin Wang, Multiagent Reinforcement Learning on Coordination Graphs, 4th International Workshop on Smart Simulation and Modelling for Complex Systems (<a href="mailto:SSMCS@IJCAI">SSMCS@IJCAI</a> 2019). (<strong>Best Paper Award****）</strong></li>
<li>Chao Yu, Dongxu Wang, Jiankang Ren, Hongwei Ge and Liang Sun. Decentralized Multiagent Reinforcement Learning for Efficient Robotic Control by Coordination Graphs. 15th Pacific Rim International Conference on Artificial Intelligence, pp. 191-203, 2018.</li>
<li>Chao Yu, Dongxu Wang, Tianpei Yang, Wenxuan Zhu, Yuchen Li, Hongwei Ge and Jiankang Ren. Adaptively Shaping Reinforcement Learning Agents via Human Reward. 15th Pacific Rim International Conference on Artificial Intelligence, pp. 85-97, 2018. (<strong>Best Paper Nomination</strong>, 5 out of 441)</li>
<li>Chao Yu, Yatong Chen, Hongtao Lv, Jiankang Ren, Hongwei Ge and Liang Sun. Neural learning for the emergence of social norms in multiagent systems. 2017 IEEE International Conference on Agents (ICA), pp. 40-45, 2017.</li>
<li>Chao Yu, Hongtao Lv, Sandip Sen, Jianye hao, Fenghui Ren and Rui Liu. An Adaptive Learning Framework for Efficient Emergence of Social Norms. 15th International Conference on Autonomous Agents and Multiagent Systems (AAMAS2016), Singapore. pp. 1307-1308, 2016.</li>
<li>Chao Yu, Hongtao Lv, Sandip Sen, Fenghui Ren and Guozhen Tan. Adaptive Learning for Efficient Emergence of Social Norms in Networked Multiagent Systems. In The Proceedings of the 14th Pacific Rim International Conference on Artificial Intelligence (PRICAI 2016): Trends in Artificial Intelligence. LNAI 9810, pp. 805-818, 2016.</li>
<li>Chao Yu, Minjie Zhang, Fenghui Ren and Xudong Luo. Emergence of Social Norms Through Collective Learning in Networked Agent Societies. The Twelfth International Conference on Autonomous Agents and Multiagent Systems (AAMAS2013) , pp.475-482, May 6-10, 2013, Saint Paul, USA.</li>
<li>Chao Yu, Fenghui Ren and Minjie Zhang. An Adaptive Bilateral Negotiation Model Based on Bayesian Learning. The 4th AAMAS International Workshop on Agent-based Complex Automated Negotiations (ACAN@AAMAS2011), <strong>The Best Student Paper Award</strong>, Taipei, 2011</li>
</ol>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/Home/home.html"> Home</a></li><li class="nav_item"><a class="nav-page" href="/Publications/publications.html"> Publications</a></li><li class="nav_item"><a class="nav-page" href="/"> About</a></li><li class="nav_item"><a class="nav-page" href="/"> Contact Us</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2023 by 余超(Yu Chao)</div><div class="theme-info">Powered by <a target="_blank" href="https://hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https://github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>